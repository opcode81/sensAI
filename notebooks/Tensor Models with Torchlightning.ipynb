{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Tensor Models with PyTorch-Lightning\n",
    "\n",
    "In this notebook we show how sensAI's TensorModel wrappers can be used together with pytorch-lightning models\n",
    "and trainers for even faster development and experimentation."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Before running the notebook\n",
    "\n",
    "Install the package and its dependencies, if you haven't done so already. E.g. for an editable install call\n",
    "```\n",
    "pip install -e .\n",
    "```\n",
    "from the root directory. You can also execute this command directly in the notebook but will need to reload the\n",
    "kernel afterwards\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note - this cell should be executed only once per session\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "\n",
    "# in order to get the top level modules; they are not part of the package\n",
    "os.chdir(\"..\")\n",
    "sys.path.append(os.path.abspath(\".\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import pytorch_lightning as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sensai.data_ingest import InputOutputArrays, DataSplitterFractional\n",
    "\n",
    "from sensai.pytorch_lightning import PLTensorToScalarClassificationModel\n",
    "from sensai.tensor_model import extractArray\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from config import get_config\n",
    "\n",
    "c  = get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the Data\n",
    "\n",
    "Unlike in the mnist-based torch-lightning tutorial, here we will load the data in a more \"realistic\" way,\n",
    "namely with pandas from disc."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(c.datafile_path(\"mnist_train.csv.zip\"))\n",
    "labels = pd.DataFrame(X.pop(\"label\"))\n",
    "X = X.values.reshape(len(X), 28, 28) / 2 ** 8\n",
    "X = pd.DataFrame({\"mnist_image\": list(X)}, index=labels.index)\n",
    "\n",
    "display(X.head())\n",
    "display(labels.head())\n",
    "\n",
    "display(\"Plotting some image from the data set\")\n",
    "some_image = X.iloc[13, 0]\n",
    "plt.imshow(some_image)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using Data Loaders in pure PyTorch Lightning\n",
    "\n",
    "First, let us see how training would proceed in pure pytorch-lightning.\n",
    "\n",
    "We will use sensaAI only for obtaining torch data loaders (which otherwise would require a few more lines of code)\n",
    "by transforming the data frames to arrays, splitting them, converting them to loaders."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "VALIDATION_FRACTION = 0.1\n",
    "\n",
    "full_ds = InputOutputArrays(extractArray(X), extractArray(labels))\n",
    "splitter = DataSplitterFractional(1-VALIDATION_FRACTION)\n",
    "\n",
    "train_ds, val_ds = splitter.split(full_ds)\n",
    "train_dataloader = train_ds.toTorchDataLoader()\n",
    "val_dataloader = val_ds.toTorchDataLoader()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have the data loaders, let us forget about sensAI for the moment. We create the model declaration and\n",
    "trainer with pytorch-lightning and fit on the MNIST data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class MNISTModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(28 * 28, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x.float()\n",
    "        x = torch.relu(self.l1(x.view(x.size(0), -1)))\n",
    "        return F.softmax(x, dim=1)\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        loss = F.cross_entropy(self(x), y)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "mnist_model = MNISTModel()\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=3, progress_bar_refresh_rate=20)\n",
    "trainer.fit(mnist_model, train_dataloader, val_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let us pick some images from the validation set and look at the results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "mini_test_set = val_dataloader.dataset[10:20]\n",
    "test_images, test_labels = mini_test_set\n",
    "\n",
    "display(mnist_model(test_images).argmax(axis=1))\n",
    "display(test_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wrapping the Model with sensAI\n",
    "\n",
    "Now let us wrap the model with sensAI interfaces. Since sensAI offers dedicated wrappers\n",
    "for pytorch-lightning models, this requires only one additional line of code.\n",
    "\n",
    "This model maps a tensor to a single label, so the correct class to wrap it with is `PLTensorToScalarClassificationModel`,\n",
    "where the `PL` prefix stands for pytorch-lightning."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mnist_model = MNISTModel()\n",
    "trainer = pl.Trainer(max_epochs=3, progress_bar_refresh_rate=20)\n",
    "sensaiMnistModel = PLTensorToScalarClassificationModel(mnist_model, trainer, validationFraction=VALIDATION_FRACTION)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "NB: Even without dedicated wrappers, it would require only a few more lines of code to get a custom implementation of\n",
    "a suitable sensAI base class that wraps one's model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the wrapped model, we can fit directly on the data bases. We don't lose any of the niceties that pytorch-lightning\n",
    "brings to the game (both the original model and the trainer are available in `sensaiMnistModel`). By wrapping the\n",
    "model and trainer we gain all the safety and transparency and flexibility in feature engineering as well\n",
    "as extensive support for model evaluation that sensAI is all about."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sensaiMnistModel.fit(X, labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The wrapped model performs predictions on data frames. Let us take some points from the training set,\n",
    "perform a prediction on them and have a look at the true labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "display(\"Predicted data frame\")\n",
    "display(sensaiMnistModel.predict(X.iloc[:5]))\n",
    "display(\"True labels data frame\")\n",
    "display(labels.iloc[:5])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluating Tensor Models\n",
    "\n",
    "TODO - the evaluation part is unfinished yet. We shold also include TensorToTensor models here\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}