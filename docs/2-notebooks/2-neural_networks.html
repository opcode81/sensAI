

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Neural Networks &#8212; sensAI Documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/sphinx-toolbox.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/js/vega@5.js"></script>
    <script src="../_static/js/vega-lite@5.js"></script>
    <script src="../_static/js/vega-embed@5.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '2-notebooks/2-neural_networks';</script>
    <link rel="canonical" href="https://tianshou.readthedocs.io/en/master/2-notebooks/2-neural_networks.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="API Reference" href="../sensai/index.html" />
    <link rel="prev" title="Introduction to sensAI: Supervised Learning with VectorModels" href="1-classification.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/sensai-logo.png" class="logo__image only-light" alt="sensAI Documentation - Home"/>
    <script>document.write(`<img src="../_static/sensai-logo.png" class="logo__image only-dark" alt="sensAI Documentation - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    Welcome to sensAI!
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../1-supervised-learning/1-vector-models.html">Models with Modular Data Pipelines</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="0_intro.html">Notebook Tutorials</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="1-classification.html">Introduction to sensAI: Supervised Learning with VectorModels</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Neural Networks</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../sensai/index.html">API Reference</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../sensai/catboost.html">catboost</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sensai/columngen.html">columngen</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sensai/distance_metric.html">distance_metric</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sensai/feature_importance.html">feature_importance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sensai/hyperopt.html">hyperopt</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sensai/lightgbm.html">lightgbm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sensai/local_search.html">local_search</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sensai/minizinc.html">minizinc</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sensai/multi_model.html">multi_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sensai/naive_bayes.html">naive_bayes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sensai/nearest_neighbors.html">nearest_neighbors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sensai/normalisation.html">normalisation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sensai/sklearn_quantile.html">sklearn_quantile</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sensai/tensor_model.html">tensor_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sensai/vector_model.html">vector_model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sensai/vectoriser.html">vectoriser</a></li>
<li class="toctree-l2"><a class="reference internal" href="../sensai/xgboost.html">xgboost</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../sensai/clustering/index.html">clustering</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../sensai/clustering/clustering_base.html">clustering_base</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/clustering/greedy_clustering.html">greedy_clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/clustering/sklearn_clustering.html">sklearn_clustering</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../sensai/data/index.html">data</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../sensai/data/dataset.html">dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/data/io_data.html">io_data</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../sensai/data_transformation/index.html">data_transformation</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../sensai/data_transformation/dft.html">dft</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/data_transformation/sklearn_transformer.html">sklearn_transformer</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/data_transformation/value_transformation.html">value_transformation</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../sensai/ensemble/index.html">ensemble</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../sensai/ensemble/ensemble_base.html">ensemble_base</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/ensemble/models.html">models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../sensai/evaluation/index.html">evaluation</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../sensai/evaluation/crossval.html">crossval</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/evaluation/eval_util.html">eval_util</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/evaluation/evaluator.html">evaluator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/evaluation/evaluator_clustering.html">evaluator_clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/evaluation/metric_computation.html">metric_computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/evaluation/result_set.html">result_set</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../sensai/evaluation/eval_stats/index.html">eval_stats</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../sensai/evaluation/eval_stats/eval_stats_base.html">eval_stats_base</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sensai/evaluation/eval_stats/eval_stats_classification.html">eval_stats_classification</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sensai/evaluation/eval_stats/eval_stats_clustering.html">eval_stats_clustering</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sensai/evaluation/eval_stats/eval_stats_regression.html">eval_stats_regression</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../sensai/feature_selection/index.html">feature_selection</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../sensai/feature_selection/rfe.html">rfe</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../sensai/featuregen/index.html">featuregen</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../sensai/featuregen/feature_generator.html">feature_generator</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/featuregen/feature_generator_registry.html">feature_generator_registry</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../sensai/geoanalytics/index.html">geoanalytics</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../sensai/geoanalytics/geo_clustering.html">geo_clustering</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/geoanalytics/geo_coords.html">geo_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/geoanalytics/local_coords.html">local_coords</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/geoanalytics/map_tiles.html">map_tiles</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../sensai/geoanalytics/geopandas/index.html">geopandas</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../sensai/geoanalytics/geopandas/coordinate_clustering.html">coordinate_clustering</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sensai/geoanalytics/geopandas/coordinate_clustering_ground_truth.html">coordinate_clustering_ground_truth</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sensai/geoanalytics/geopandas/coordinates.html">coordinates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sensai/geoanalytics/geopandas/geometry.html">geometry</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sensai/geoanalytics/geopandas/graph.html">graph</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../sensai/pytorch_lightning/index.html">pytorch_lightning</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../sensai/pytorch_lightning/pl_models.html">pl_models</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../sensai/sklearn/index.html">sklearn</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../sensai/sklearn/sklearn_base.html">sklearn_base</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/sklearn/sklearn_classification.html">sklearn_classification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/sklearn/sklearn_regression.html">sklearn_regression</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../sensai/tensorflow/index.html">tensorflow</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../sensai/tensorflow/tf_base.html">tf_base</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/tensorflow/tf_mlp.html">tf_mlp</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../sensai/torch/index.html">torch</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../sensai/torch/torch_base.html">torch_base</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/torch/torch_data.html">torch_data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/torch/torch_enums.html">torch_enums</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/torch/torch_eval_util.html">torch_eval_util</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/torch/torch_modules.html">torch_modules</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/torch/torch_opt.html">torch_opt</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/torch/torchtext.html">torchtext</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../sensai/torch/torch_models/index.html">torch_models</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../sensai/torch/torch_models/lstnet/index.html">lstnet</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sensai/torch/torch_models/mlp/index.html">mlp</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sensai/torch/torch_models/residualffn/index.html">residualffn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../sensai/torch/torch_models/seq/index.html">seq</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../sensai/tracking/index.html">tracking</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../sensai/tracking/azure_tracking.html">azure_tracking</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/tracking/clearml_tracking.html">clearml_tracking</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/tracking/mlflow_tracking.html">mlflow_tracking</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/tracking/tracking_base.html">tracking_base</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../sensai/util/index.html">util</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/aggregation.html">aggregation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/cache.html">cache</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/cache_azure.html">cache_azure</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/cache_mysql.html">cache_mysql</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/datastruct.html">datastruct</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/deprecation.html">deprecation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/dtype.html">dtype</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/hash.html">hash</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/helper.html">helper</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/io.html">io</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/jscode.html">jscode</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/logging.html">logging</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/math.html">math</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/multiprocessing.html">multiprocessing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/pandas.html">pandas</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/pickle.html">pickle</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/plot.html">plot</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/profiling.html">profiling</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/sequences.html">sequences</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/string.html">string</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/test.html">test</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/time.html">time</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/typing.html">typing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../sensai/util/version.html">version</a></li>
</ul>
</li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/thu-ml/tianshou/blob/master/docs/2-notebooks/2-neural_networks.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/2-notebooks/2-neural_networks.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Neural Networks</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-classification">Image Classification</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#applying-predefined-models">Applying Predefined Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-a-custom-cnn-model">Creating a Custom CNN Model</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wrapping-a-custom-torch-nn-module-instance">Wrapping a Custom torch.nn.Module Instance</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-an-input-output-adaptive-custom-model">Creating an Input-/Output-Adaptive Custom Model</a></li>
</ul>
</li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="neural-networks">
<h1>Neural Networks<a class="headerlink" href="#neural-networks" title="Permalink to this heading">#</a></h1>
<p>Neural networks being a very powerful class of models, especially in cases where the learning of representations from low-level information (such as pixels, audio samples or text) is key, sensAI provides many useful abstractions for dealing with this class of models, facilitating data handling, learning and evaluation.</p>
<p>sensAI mainly provides abstractions for PyTorch, but there is also rudimentary support for TensorFlow.</p>
<div class="cell tag_hide-cell docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell content</span>
<span class="expanded">Hide code cell content</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>
</div>
</div>
</details>
</div>
<div class="cell tag_hide-cell docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell content</span>
<span class="expanded">Hide code cell content</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%capture</span>
<span class="kn">import</span> <span class="nn">sys</span><span class="p">;</span> <span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="s2">&quot;../src&quot;</span><span class="p">,</span> <span class="s2">&quot;..&quot;</span><span class="p">])</span>
<span class="kn">import</span> <span class="nn">sensai</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">config</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">functools</span>

<span class="n">cfg</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
<span class="n">sensai</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">configure</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
</div>
<section id="image-classification">
<h2>Image Classification<a class="headerlink" href="#image-classification" title="Permalink to this heading">#</a></h2>
<p>As an example use case, let us solve the classification problem of classifying digits in pixel images from the MNIST dataset. Images are greyscale (no colour information) and 28x28 pixels in size.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mnist_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">datafile_path</span><span class="p">(</span><span class="s2">&quot;mnist_train.csv.zip&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>The data frame contains one column for every pixel, each pixel being represented by an 8-bit integer (0 to 255).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mnist_df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>label</th>
      <th>1x1</th>
      <th>1x2</th>
      <th>1x3</th>
      <th>1x4</th>
      <th>1x5</th>
      <th>1x6</th>
      <th>1x7</th>
      <th>1x8</th>
      <th>1x9</th>
      <th>...</th>
      <th>28x19</th>
      <th>28x20</th>
      <th>28x21</th>
      <th>28x22</th>
      <th>28x23</th>
      <th>28x24</th>
      <th>28x25</th>
      <th>28x26</th>
      <th>28x27</th>
      <th>28x28</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>5</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 785 columns</p>
</div></div></div>
</div>
<p>Let’s create the I/O data for our experiments.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mnistIoData</span> <span class="o">=</span> <span class="n">sensai</span><span class="o">.</span><span class="n">InputOutputData</span><span class="o">.</span><span class="n">from_data_frame</span><span class="p">(</span><span class="n">mnist_df</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now that we have the image data separated from the labels, let’s write a function to restore the 2D image arrays and take a look at some of the images.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">reshape_2d_image</span><span class="p">(</span><span class="n">series</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">series</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">reshape_2d_image</span><span class="p">(</span><span class="n">mnistIoData</span><span class="o">.</span><span class="n">inputs</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">]),</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;binary&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/5ff4f851b7f9d60cb15739740c19ad6d9467abb80e57ffef816737ef862251dd.png" src="../_images/5ff4f851b7f9d60cb15739740c19ad6d9467abb80e57ffef816737ef862251dd.png" />
</div>
</div>
<section id="applying-predefined-models">
<h3>Applying Predefined Models<a class="headerlink" href="#applying-predefined-models" title="Permalink to this heading">#</a></h3>
<p>We create an evaluator in order to test the performance of our models, randomly splitting the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">evaluator_params</span> <span class="o">=</span> <span class="n">sensai</span><span class="o">.</span><span class="n">evaluation</span><span class="o">.</span><span class="n">ClassificationEvaluatorParams</span><span class="p">(</span><span class="n">fractional_split_test_fraction</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">eval_util</span> <span class="o">=</span> <span class="n">sensai</span><span class="o">.</span><span class="n">evaluation</span><span class="o">.</span><span class="n">ClassificationModelEvaluation</span><span class="p">(</span><span class="n">mnistIoData</span><span class="p">,</span> <span class="n">evaluator_params</span><span class="o">=</span><span class="n">evaluator_params</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>One pre-defined model we could try is a simple multi-layer perceptron. A PyTorch-based implementation is provided via class <code class="docutils literal notranslate"><span class="pre">MultiLayerPerceptronVectorClassificationModel</span></code>. This implementation supports CUDA-accelerated computations (on Nvidia GPUs), yet we shall stick to CPU-based computation (cuda=False) in this tutorial.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sensai.torch</span>

<span class="n">nn_optimiser_params</span> <span class="o">=</span> <span class="n">sensai</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">NNOptimiserParams</span><span class="p">(</span><span class="n">early_stopping_epochs</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">54</span><span class="p">)</span>
<span class="n">torch_mlp_model</span> <span class="o">=</span> <span class="n">sensai</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">MultiLayerPerceptronVectorClassificationModel</span><span class="p">(</span><span class="n">hidden_dims</span><span class="o">=</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span>
        <span class="n">cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">normalisation_mode</span><span class="o">=</span><span class="n">sensai</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">NormalisationMode</span><span class="o">.</span><span class="n">MAX_ALL</span><span class="p">,</span>
        <span class="n">nn_optimiser_params</span><span class="o">=</span><span class="n">nn_optimiser_params</span><span class="p">,</span> <span class="n">p_dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">with_name</span><span class="p">(</span><span class="s2">&quot;MLP&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Neural networks work best on <strong>normalised inputs</strong>, so we have opted to apply basic normalisation by specifying a normalisation mode which will transforms inputs by dividing by the maximum value found across all columns in the training data. For more elaborate normalisation options, we could have used a data frame transformer (DFT), particularly <code class="docutils literal notranslate"><span class="pre">DFTNormalisation</span></code> or <code class="docutils literal notranslate"><span class="pre">DFTSkLearnTransformer</span></code>.</p>
<p>sensAI’s default <strong>neural network training algorithm</strong> is based on early stopping, which involves checking, in regular intervals, the performance of the model on a validation set (which is split from the training set) and ultimately selecting the model that performed best on the validation set. You have full control over the loss evaluation method used to select the best model (by passing a respective <code class="docutils literal notranslate"><span class="pre">NNLossEvaluator</span></code> instance to NNOptimiserParams) as well as the method that is used to split the training set into the actual training set and the validation set (by adding a <code class="docutils literal notranslate"><span class="pre">DataFrameSplitter</span></code> to the model or using a custom <code class="docutils literal notranslate"><span class="pre">TorchDataSetProvider</span></code>).</p>
<p>Given the vectorised nature of our MNIST dataset, we can apply any type of model which can accept the numeric inputs. Let’s compare the neural network we defined above against another pre-defined model, which is based on a scikit-learn implementation and uses decision trees rather than neural networks.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random_forest_model</span> <span class="o">=</span> <span class="n">sensai</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">classification</span><span class="o">.</span><span class="n">SkLearnRandomForestVectorClassificationModel</span><span class="p">(</span>
        <span class="n">min_samples_leaf</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">with_name</span><span class="p">(</span><span class="s2">&quot;RandomForest&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s compare the two models using our evaluation utility.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">eval_util</span><span class="o">.</span><span class="n">compare_models</span><span class="p">([</span><span class="n">random_forest_model</span><span class="p">,</span> <span class="n">torch_mlp_model</span><span class="p">]);</span>
</pre></div>
</div>
</div>
</div>
<p>Both models perform reasonably well.</p>
</section>
<section id="creating-a-custom-cnn-model">
<h3>Creating a Custom CNN Model<a class="headerlink" href="#creating-a-custom-cnn-model" title="Permalink to this heading">#</a></h3>
<p>Given that this is an image recognition problem, it can be sensible to apply convolutional neural networks (CNNs), which can analyse patches of the image in order to generate more high-level features from them.
Specifically, we shall apply a neural network model which uses multiple convolutions, a max-pooling layer and a multi-layer perceptron at the end in order to produce the classification.</p>
<p>For classification and regression, sensAI provides the fundamental classes <code class="docutils literal notranslate"><span class="pre">TorchVectorClassificationModel</span></code> and <code class="docutils literal notranslate"><span class="pre">TorchVectorRegressionModel</span></code> respectively. Ultimately, these classes will wrap an instance of <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>, the base class for neural networks in PyTorch.</p>
<section id="wrapping-a-custom-torch-nn-module-instance">
<h4>Wrapping a Custom torch.nn.Module Instance<a class="headerlink" href="#wrapping-a-custom-torch-nn-module-instance" title="Permalink to this heading">#</a></h4>
<p>If we already had an implementation of a <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>, it can be straightforwardly adapted to become a sensAI <code class="docutils literal notranslate"><span class="pre">VectorModel</span></code>.</p>
<p>Let’s say we had the following implementation of a torch module, which performs the steps described above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="k">class</span> <span class="nc">MnistCnnModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num_conv</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">pooling_kernel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
            <span class="n">mlp_hidden_dims</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">output_activation_fn</span><span class="p">:</span> <span class="n">sensai</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">ActivationFunction</span><span class="p">,</span> <span class="n">p_dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">k</span> <span class="o">=</span> <span class="n">kernel_size</span>
        <span class="n">p</span> <span class="o">=</span> <span class="n">pooling_kernel_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cnn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_conv</span><span class="p">,</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">k</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">p_dropout</span><span class="p">)</span>
        <span class="n">reduced_dim</span> <span class="o">=</span> <span class="p">(</span><span class="n">image_dim</span> <span class="o">-</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">p</span>
        <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">reduced_dim</span><span class="p">)</span> <span class="o">!=</span> <span class="n">reduced_dim</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pooling kernel size </span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s2"> is not a divisor of post-convolution dimension </span><span class="si">{</span><span class="n">image_dim</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">sensai</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">MultiLayerPerceptron</span><span class="p">(</span><span class="n">num_conv</span> <span class="o">*</span> <span class="nb">int</span><span class="p">(</span><span class="n">reduced_dim</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">mlp_hidden_dims</span><span class="p">,</span>
            <span class="n">output_activation_fn</span><span class="o">=</span><span class="n">output_activation_fn</span><span class="o">.</span><span class="n">get_torch_function</span><span class="p">(),</span>
            <span class="n">hid_activation_fn</span><span class="o">=</span><span class="n">sensai</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">ActivationFunction</span><span class="o">.</span><span class="n">RELU</span><span class="o">.</span><span class="n">get_torch_function</span><span class="p">(),</span>
            <span class="n">p_dropout</span><span class="o">=</span><span class="n">p_dropout</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cnn</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Since this module requires 2D images as input, we will need a component that transforms the vector input that is given in our data frame into a tensor that will serve as input to the module.
In sensAI, the abstraction for this purpose is a <code class="docutils literal notranslate"><span class="pre">sensai.torch.Tensoriser</span></code>. A <strong>Tensoriser</strong> can, in principle, perform arbitrary computations in order to produce, from a data frame with N rows, one or more tensors of length N (first dimension equal to N) that will ultimately be fed to the neural network.</p>
<p>Luckily, for the case at hand, we already have the function <code class="docutils literal notranslate"><span class="pre">reshape_2d_image</span></code> from above to assist in the implementation of the tensoriser.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ImageReshapingInputTensoriser</span><span class="p">(</span><span class="n">sensai</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">RuleBasedTensoriser</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">_tensorise</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
        <span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">reshape_2d_image</span><span class="p">(</span><span class="n">row</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">iterrows</span><span class="p">()]</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">images</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">/</span> <span class="mi">255</span>
</pre></div>
</div>
</div>
</div>
<p>In this case, we derived the class from <code class="docutils literal notranslate"><span class="pre">RuleBasedTensoriser</span></code> rather than <code class="docutils literal notranslate"><span class="pre">Tensoriser</span></code>, because our tensoriser does not require fitting. We additionally took care of the normalisation.</p>
<p>Now we have all we need to create a sensAI <code class="docutils literal notranslate"><span class="pre">TorchVectorClassificationModel</span></code> that will work on the input/output data we loaded earlier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cnn_module</span> <span class="o">=</span> <span class="n">MnistCnnModule</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> <span class="n">sensai</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">ActivationFunction</span><span class="o">.</span><span class="n">LOG_SOFTMAX</span><span class="p">)</span>
<span class="n">nn_optimiser_params</span> <span class="o">=</span> <span class="n">sensai</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">NNOptimiserParams</span><span class="p">(</span>
    <span class="n">optimiser</span><span class="o">=</span><span class="n">sensai</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">Optimiser</span><span class="o">.</span><span class="n">ADAMW</span><span class="p">,</span>
    <span class="n">optimiser_lr</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="n">early_stopping_epochs</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">cnn_model_from_module</span> <span class="o">=</span> <span class="n">sensai</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">TorchVectorClassificationModel</span><span class="o">.</span><span class="n">from_module</span><span class="p">(</span>
        <span class="n">cnn_module</span><span class="p">,</span> <span class="n">sensai</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">ClassificationOutputMode</span><span class="o">.</span><span class="n">LOG_PROBABILITIES</span><span class="p">,</span>
        <span class="n">cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">nn_optimiser_params</span><span class="o">=</span><span class="n">nn_optimiser_params</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">with_input_tensoriser</span><span class="p">(</span><span class="n">ImageReshapingInputTensoriser</span><span class="p">())</span> \
    <span class="o">.</span><span class="n">with_name</span><span class="p">(</span><span class="s2">&quot;CNN&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We have now fully defined all the necessary parameters, including parameters controlling the training of the model.</p>
<p>We are now ready to evaluate the model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">eval_util</span><span class="o">.</span><span class="n">perform_simple_evaluation</span><span class="p">(</span><span class="n">cnn_model_from_module</span><span class="p">);</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="creating-an-input-output-adaptive-custom-model">
<h4>Creating an Input-/Output-Adaptive Custom Model<a class="headerlink" href="#creating-an-input-output-adaptive-custom-model" title="Permalink to this heading">#</a></h4>
<p>While the above approach allows us to straightforwardly encapsulate a <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>, it really doesn’t follow sensAI’s principle of adapting model hyperparameters based on the inputs and outputs we receive during training - whenever possible. Notice that in the above example, we had to hard-code the image dimension (<code class="docutils literal notranslate"><span class="pre">28</span></code>) as well as the number of classes (<code class="docutils literal notranslate"><span class="pre">10</span></code>), even though these parameters could have been easily determined from the data. Especially in other domains where feature engineering is possible, we might want to experiment with different combinations of features, and therefore automatically adapting to inputs is key if we want to avoid editing the model hyperparameters time and time again; similarly, we might change the set of target labels in our classification problem and the model should simply adapt to a changed output dimension.</p>
<p>To design a model that can fully adapt to the inputs and outputs, we can simply subclass <code class="docutils literal notranslate"><span class="pre">TorchVectorClassificationModel</span></code>, where the late instantiation of the underlying model is catered for. Naturally, delayed construction of the underlying model necessitates the use of factories and thus results in some indirections.</p>
<p>If we had designed the above model to be within the sensAI <code class="docutils literal notranslate"><span class="pre">VectorModel</span></code> realm from the beginning, here’s what we might have written:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="k">class</span> <span class="nc">CnnModel</span><span class="p">(</span><span class="n">sensai</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">TorchVectorClassificationModel</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cuda</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">num_conv</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">pooling_kernel_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">mlp_hidden_dims</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
            <span class="n">nn_optimiser_params</span><span class="p">:</span> <span class="n">sensai</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">NNOptimiserParams</span><span class="p">,</span> <span class="n">p_dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cuda</span> <span class="o">=</span> <span class="n">cuda</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_activation_fn</span> <span class="o">=</span> <span class="n">sensai</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">ActivationFunction</span><span class="o">.</span><span class="n">LOG_SOFTMAX</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kernel_size</span> <span class="o">=</span> <span class="n">kernel_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_conv</span> <span class="o">=</span> <span class="n">num_conv</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pooling_kernel_size</span> <span class="o">=</span> <span class="n">pooling_kernel_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp_hidden_dims</span> <span class="o">=</span> <span class="n">mlp_hidden_dims</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p_dropout</span> <span class="o">=</span> <span class="n">p_dropout</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">sensai</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">ClassificationOutputMode</span><span class="o">.</span><span class="n">for_activation_fn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_activation_fn</span><span class="p">),</span>
            <span class="n">torch_model_factory</span><span class="o">=</span><span class="n">functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">VectorTorchModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">),</span>
            <span class="n">nn_optimiser_params</span><span class="o">=</span><span class="n">nn_optimiser_params</span><span class="p">)</span>

    <span class="k">class</span> <span class="nc">VectorTorchModel</span><span class="p">(</span><span class="n">sensai</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">VectorTorchModel</span><span class="p">):</span>
        <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">parent</span><span class="p">:</span> <span class="s2">&quot;CnnModel&quot;</span><span class="p">):</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">parent</span><span class="o">.</span><span class="n">cuda</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_parent</span> <span class="o">=</span> <span class="n">parent</span>

        <span class="k">def</span> <span class="nf">create_torch_module_for_dims</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">Module</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">input_dim</span><span class="p">)),</span> <span class="n">output_dim</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_parent</span><span class="p">)</span>

        <span class="k">class</span> <span class="nc">Module</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
            <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">parent</span><span class="p">:</span> <span class="s2">&quot;CnnModel&quot;</span><span class="p">):</span>
                <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
                <span class="n">k</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">kernel_size</span>
                <span class="n">p</span> <span class="o">=</span> <span class="n">parent</span><span class="o">.</span><span class="n">pooling_kernel_size</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cnn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">parent</span><span class="o">.</span><span class="n">num_conv</span><span class="p">,</span> <span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">k</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">((</span><span class="n">p</span><span class="p">,</span> <span class="n">p</span><span class="p">))</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">parent</span><span class="o">.</span><span class="n">p_dropout</span><span class="p">)</span>
                <span class="n">reduced_dim</span> <span class="o">=</span> <span class="p">(</span><span class="n">image_dim</span> <span class="o">-</span> <span class="n">k</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">p</span>
                <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">reduced_dim</span><span class="p">)</span> <span class="o">!=</span> <span class="n">reduced_dim</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Pooling kernel size </span><span class="si">{</span><span class="n">p</span><span class="si">}</span><span class="s2"> is not a divisor of post-convolution dimension </span><span class="si">{</span><span class="n">image_dim</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">sensai</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">MultiLayerPerceptron</span><span class="p">(</span><span class="n">parent</span><span class="o">.</span><span class="n">num_conv</span> <span class="o">*</span> <span class="nb">int</span><span class="p">(</span><span class="n">reduced_dim</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">parent</span><span class="o">.</span><span class="n">mlp_hidden_dims</span><span class="p">,</span>
                    <span class="n">output_activation_fn</span><span class="o">=</span><span class="n">parent</span><span class="o">.</span><span class="n">output_activation_fn</span><span class="o">.</span><span class="n">get_torch_function</span><span class="p">(),</span>
                    <span class="n">hid_activation_fn</span><span class="o">=</span><span class="n">sensai</span><span class="o">.</span><span class="n">torch</span><span class="o">.</span><span class="n">ActivationFunction</span><span class="o">.</span><span class="n">RELU</span><span class="o">.</span><span class="n">get_torch_function</span><span class="p">(),</span>
                    <span class="n">p_dropout</span><span class="o">=</span><span class="n">parent</span><span class="o">.</span><span class="n">p_dropout</span><span class="p">)</span>

            <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
                <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cnn</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
                <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>It is only insignificantly more code than in the previous implementation.
The outer class, which provides the sensAI <code class="docutils literal notranslate"><span class="pre">VectorModel</span></code> features, serves mainly to hold the parameters, and the inner class inheriting from <code class="docutils literal notranslate"><span class="pre">VectorTorchModel</span></code> serves as a factory for the <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code>, providing us with the input and output dimensions (number of input columns and number of classes respectively) based on the data, thus enabling the model to adapt. If we had required even more adaptiveness, we could have learnt more about the data from within the fitting process of a custom input tensoriser (i.e. we could have added an inner <code class="docutils literal notranslate"><span class="pre">Tensoriser</span></code> class, which could have derived further hyperparameters from the data in its implementation of the fitting method.)</p>
<p>Let’s instantiate our model and evaluate it.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cnn_model</span> <span class="o">=</span> <span class="n">CnnModel</span><span class="p">(</span><span class="n">cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">num_conv</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">pooling_kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">mlp_hidden_dims</span><span class="o">=</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span><span class="mi">20</span><span class="p">),</span>
        <span class="n">nn_optimiser_params</span><span class="o">=</span><span class="n">nn_optimiser_params</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">with_name</span><span class="p">(</span><span class="s2">&quot;CNN&#39;&quot;</span><span class="p">)</span> \
    <span class="o">.</span><span class="n">with_input_tensoriser</span><span class="p">(</span><span class="n">ImageReshapingInputTensoriser</span><span class="p">())</span>

<span class="n">eval_data</span> <span class="o">=</span> <span class="n">eval_util</span><span class="o">.</span><span class="n">perform_simple_evaluation</span><span class="p">(</span><span class="n">cnn_model</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Our CNN models do improve upon the MLP model we evaluated earlier. Let’s do a comparison of all the models we trained thus far:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">comparison_data</span> <span class="o">=</span> <span class="n">eval_util</span><span class="o">.</span><span class="n">compare_models</span><span class="p">([</span><span class="n">torch_mlp_model</span><span class="p">,</span> <span class="n">cnn_model_from_module</span><span class="p">,</span> <span class="n">cnn_model</span><span class="p">,</span> <span class="n">random_forest_model</span><span class="p">],</span> <span class="n">fit_models</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">comparison_data</span><span class="o">.</span><span class="n">results_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>accuracy</th>
      <th>balancedAccuracy</th>
    </tr>
    <tr>
      <th>model_name</th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>MLP</th>
      <td>0.962250</td>
      <td>0.961897</td>
    </tr>
    <tr>
      <th>CNN</th>
      <td>0.978333</td>
      <td>0.978435</td>
    </tr>
    <tr>
      <th>CNN'</th>
      <td>0.977167</td>
      <td>0.977261</td>
    </tr>
    <tr>
      <th>RandomForest</th>
      <td>0.946667</td>
      <td>0.945917</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Note that any differences between the two CNN models are due only to randomness in the parameter initialisation; they are functionally identical.</p>
<p>Could the CNN model have produced even better results? Let’s take a look at some examples where the CNN model went wrong by inspecting the evaluation data that was returned earlier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">misclassified</span> <span class="o">=</span> <span class="n">eval_data</span><span class="o">.</span><span class="n">get_misclassified_triples_pred_true_input</span><span class="p">()</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axs</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">predClass</span><span class="p">,</span> <span class="n">trueClass</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">misclassified</span><span class="p">[:</span><span class="mi">9</span><span class="p">]):</span>
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="o">//</span><span class="mi">3</span><span class="p">][</span><span class="n">i</span><span class="o">%</span><span class="k">3</span>].imshow(reshape_2d_image(input), cmap=&quot;binary&quot;)
    <span class="n">axs</span><span class="p">[</span><span class="n">i</span><span class="o">//</span><span class="mi">3</span><span class="p">][</span><span class="n">i</span><span class="o">%</span><span class="k">3</span>].set_title(f&quot;{trueClass} misclassified as {predClass}&quot;)
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/e9929b583960c357476e97ad8e0b9ec3660c2aa74c1b31397cbb3ea0f08ebc7d.png" src="../_images/e9929b583960c357476e97ad8e0b9ec3660c2aa74c1b31397cbb3ea0f08ebc7d.png" />
</div>
</div>
<p>While some of these examples are indeed ambiguous, there still is room for improvement.</p>
</section>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./2-notebooks"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="1-classification.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Introduction to sensAI: Supervised Learning with VectorModels</p>
      </div>
    </a>
    <a class="right-next"
       href="../sensai/index.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">API Reference</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#image-classification">Image Classification</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#applying-predefined-models">Applying Predefined Models</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-a-custom-cnn-model">Creating a Custom CNN Model</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#wrapping-a-custom-torch-nn-module-instance">Wrapping a Custom torch.nn.Module Instance</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#creating-an-input-output-adaptive-custom-model">Creating an Input-/Output-Adaptive Custom Model</a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By sensAI contributors
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2019-2024 by sensAI contributors.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>